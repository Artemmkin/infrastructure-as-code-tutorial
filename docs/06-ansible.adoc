= Ansible

In the previous lab, you used Terraform to implement Infrastructure as Code approach to managing the cloud infrastructure resources.
There is another major type of tooling we need to consider,   and that is *Configuration Management* (CM) tools.

When talking about CM tools, we can often meet the acronym `CAPS` which stands for Chef, Ansible, Puppet and Saltstack - the most known and commonly used CM tools.
In this lab, we're going to look at Ansible and see how CM tools can help us improve our operations.

== Intro

If you think about our current operations and what else there is to improve, you will probably see the potential problem in the deployment process.

The way we do deployment right now is by connecting via SSH to a VM and running a deployment script.
And the problem here is not the connecting via SSH part, but running a script.

_Scripts are bad at long term management of system configuration, because they make common system configuration operations complex and error-prone._

When you write a script, you use a scripting language syntax (Bash, Python) to write commands which you think should change the system's configuration.
And the problem is that there are too many ways people can write the code that is meant to do the same things, which is the reason why scripts are often difficult to read and understand.
Besides, there are various choices as to what language to use for a script: should you write it in Ruby which your colleagues know very well or Bash which you know better?

Common configuration management operations are well-known: copy a file to a remote machine, create a folder, start/stop/enable a process, install packages, etc.
So _we need a tool that would implement these common operations in a well-known and tested way, providing us with a clean and understandable syntax for using them_.
This way we wouldn't have to write complex scripts ourselves each time for the same tasks, possibly making mistakes along the way, but instead just tell the tool what should be done: what packages should be present, what processes should be started, etc.

This is exactly what CM tools do.
So let's check it out using Ansible as an example.

== Install Ansible

NOTE: this lab assumes Ansible v2.4 is installed.
It may not work as expected with other versions as things change quickly.

Issue the following commands in the Google cloud shell (note that Ansible will not remain installed when your shell goes to sleep):

[source,bash]
----
$ sudo apt update
$ sudo apt install software-properties-common
$ sudo apt-add-repository --yes --update ppa:ansible/ansible
$ sudo apt install -y ansible
----

If you have issues, reference the instructions on how to install Ansible on your system from http://docs.ansible.com/ansible/latest/intro_installation.html[official documentation].

Verify that Ansible was installed by checking the version:

[source,bash]
----
$ ansible --version
----

== Infrastructure as Code project

Create a new directory called `06-ansible` inside your `iac-tutorial` repo, which we'll use to save the work done in this lab.

== Provision compute resources

Start a VM and create other GCP resources for running your application applying Terraform configuration you wrote in the previous lab (destroy first if you have some still running):

[source,bash]
----
$ cd ./05-terraform  # adapt this command as necessary to get to the directory
$ terraform apply -auto-approve
----

== Deploy playbook

We'll rewrite our Bash script used for deployment using Ansible syntax.

Ansible uses *tasks* to define commands used for system configuration.
Each Ansible task basically corresponds to one command in our Bash script.

Each task uses some *module* to perform a certain operation on the configured system.
Modules are well tested functions which are meant to perform common system configuration operations.

Let's look at our `install.sh` first to see what modules we might need to use:

[source,bash]
----
#!/bin/bash
set -e  # exit immediately if anything returns non-zero. See https://www.javatpoint.com/linux-set-command


echo "  ----- download, initialize, and run app -----  "
git clone https://github.com/dm-academy/node-svc-v1
cd node-svc-v1
git checkout 02
npm install
npm install express
----

We clearly see here several types of operations: cloning a git repo and setting the branch, initializing npm, and installing express (a Node package).

We also, to start the service, need to run this command:

`$ sudo nodejs /home/node-user/node-svc-v1/server.js &`

So we'll search for Ansible modules that allow to perform these operations.
Luckily, there are modules for all of these operations.

Ansible uses YAML syntax to define tasks, which makes the configuration readable.

Let's create a file called `deploy.yml` ("deploy" including both installation and launching) inside the `ansible` directory:

[source,yaml]
----
---
- name: Deploy node-svc App
  hosts: node-svc
  tasks:
    - name: Fetch the latest version of application code
    # see https://docs.ansible.com/ansible/latest/modules/git_module.html
      git:
        repo: 'https://github.com/dm-academy/node-svc-v1'
        dest: /home/node-user/node-svc-1
        version: "02"
      register: clone

    - name: NPM install express and initialize app
    # see https://docs.ansible.com/ansible/latest/modules/npm_module.html
      npm:
        name: express
        global: yes

    - name: Install packages based on package.json.
      npm:
        path: /home/node-user/node-svc-1

    - name: Start the nodejs server
    # see https://codelike.pro/deploy-nodejs-app-with-ansible-git-pm2/
      sudo_user: node-user
      command: pm2 start server.js --name node-app chdir=/home/node-user/node-svc-1s
      ignore_errors: yes
      when: npm_finished.changed
----

In this configuration file, which is called a *playbook* in Ansible terminology, we define several tasks.

The `name` that precedes each task is used as a comment that will show up in the terminal when the task starts to run.

`register` option allows to capture the result output from running a task.

The `first task` uses git module to pull the code from GitHub.

[source,yaml]
----
- name: Fetch the latest version of application code
    # see https://docs.ansible.com/ansible/latest/modules/git_module.html
      git:
        repo: 'https://github.com/dm-academy/node-svc-v1'
        dest: /home/node-user/node-svc-1
        version: 02
        register: git_finished
----

The second task installs the npm package express and initializes the app in the specified directory:

[source,yaml]
----

    - name: NPM install express and initialize app
    # see https://docs.ansible.com/ansible/latest/modules/npm_module.html
      npm:
        name: coffee-script
        global: yes

    - name: Install packages based on package.json.
      npm:
        path: /home/node-user/node-svc-1
----

The third task runs the server:

[source,yaml]
----
    - name: Start the nodejs server
    # see https://codelike.pro/deploy-nodejs-app-with-ansible-git-pm2/
      sudo_user: node-user
      command: pm2 start server.js --name node-app chdir=/home/node-user/node-svc-1s
      ignore_errors: yes
      when: npm_finished.changed
----

Note, how for each module we use a different set of module options.
You can find full information about the options in a module's documentation.

In the second task, we use a conditional statement http://docs.ansible.com/ansible/latest/playbooks_conditionals.html#the-when-statement[when] to make sure the `npm install` task is only run when the local repo was updated, i.e.
the output from running git clone command was changed.
This allows us to save some time spent on system configuration by not running unnecessary commands.

On the same level as tasks, we also define a *handlers* block.
Handlers are special tasks which are run only in response to notification events from other tasks.
In our case, `node-svc` service gets restarted only when the `npm install` task is run.

== Inventory file

The way that Ansible works is simple: it connects to a remote VM (usually via SSH) and runs the commands that stand behind each module you used in your playbook.

To be able to connect to a remote VM, Ansible needs information like IP address and credentials.
This information is defined in a special file called http://docs.ansible.com/ansible/latest/intro_inventory.html[inventory].

Create a file called `hosts.yml` inside `ansible` directory with the following content (make sure to change the `ansible_host` parameter to public IP of your VM):

[source,yaml]
----
node-svc:
  hosts:
    node-svc-01:
      ansible_host: 35.35.35.35
      ansible_user: node-user
----

Here we define a group of hosts (`node-svc`) under which we list the hosts that belong to this group.
In this case, we list only one host under the hosts group and give it a name (`node-svc-01`) and information on how to connect to the host.

Now note, that inside our `deploy.yml` playbook we specified `node-svc` host group in the `hosts` option before the tasks:

[source,yaml]
----
---
- name: Deploy node-svc app
  hosts: node-svc-01
  tasks:
  ...
----

This will tell Ansible to run the following tasks on the hosts defined in hosts group `raddit-app`.

== Ansible configuration

Before we can run a deployment, we need to make some configuration changes to how Ansible views and manages our `ansible` directory.

Let's define custom Ansible configuration for our directory.
Create a file called `ansible.cfg` inside the `ansible` directory with the following content:

[source,ini]
----
[defaults]
inventory = ./hosts.yml
private_key_file = ~/.ssh/node-user
host_key_checking = False
----

This custom configuration will tell Ansible what inventory file to use, what private key file to use for SSH connection and to skip the host checking key procedure.

== Run playbook

Now it's time to run your playbook and see how it works.

Use the following commands to start a deployment:

[source,bash]
----
$ cd ./06-ansible
$ ansible-playbook deploy.yml
----

== Access Application

Access the application in your browser by its public IP (don't forget to specify the port 3000) and make sure application has been deployed and is functional.

== Futher Learning Ansible

There's a whole lot to learn about Ansible.
Try playing around with it more and create a `playbook` which provides the same system configuration as your `configuration.sh` script.
Save it under the name `configuration.yml` inside the `ansible` folder, then use it inside https://www.packer.io/docs/provisioners/ansible.html[ansible provisioner] instead of shell in your Packer template.

You can find an example of `configuration.yml` playbook https://github.com/Artemmkin/infrastructure-as-code-example/blob/master/ansible/configuration.yml[here].

And https://github.com/Artemmkin/infrastructure-as-code-example/blob/master/packer/raddit-base-image-ansible.json[here] is an example of a Packer template which uses ansible provisioner.

== Save and commit the work

Save and commit the `ansible` folder created in this lab into your `iac-tutorial` repo.

== Idempotence

One more advantage of CM tools over scripts is that commands they implement designed to be *idempotent* by default.

Idempotence in this case means that even if you apply the same configuration changes multiple times the result will stay the same.

This is important because some commands that you use in scripts may not produce the same results when run more than once.
So we always want to achieve idempotence for our configuration management system, sometimes applying conditionals statements as we did in this lab.

== Conclusion

Ansible provided us with a clean YAML syntax for performing common system configuration tasks.
This allowed us to get rid of our own implementation of configuration commands.

It might not seem like a big improvement at this scale, because our deploy script is small, but it definitely brings order to system configuration management and is more noticeable at medium and large scale.

Destroy the resources created by Terraform.

[source,bash]
----
$ terraform destroy
----

Next: xref:07-vagrant.adoc[Vagrant]
